{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892b1505",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Define the URL for the dataset\n",
    "url = \"https://raw.githubusercontent.com/alexeygrigorev/datasets/master/car_fuel_efficiency.csv\"\n",
    "\n",
    "# 1. Load the dataset\n",
    "print(\"Loading data from:\", url)\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# 2. Select only the specified columns\n",
    "required_columns = [\n",
    "    'engine_displacement',\n",
    "    'horsepower',\n",
    "    'vehicle_weight',\n",
    "    'model_year',\n",
    "    'fuel_efficiency_mpg'\n",
    "]\n",
    "df_subset = df[required_columns]\n",
    "\n",
    "print(\"\\nDataset Head (Subset):\")\n",
    "print(df_subset.head())\n",
    "print(\"\\nDataset Info (Subset):\")\n",
    "print(df_subset.info())\n",
    "\n",
    "# 3. EDA on 'fuel_efficiency_mpg'\n",
    "target_variable = 'fuel_efficiency_mpg'\n",
    "print(f\"\\n--- EDA for Target Variable: {target_variable} ---\")\n",
    "\n",
    "# Calculate and print basic statistics and skewness\n",
    "target_stats = df_subset[target_variable].describe()\n",
    "print(target_stats)\n",
    "\n",
    "skewness = df_subset[target_variable].skew()\n",
    "print(f\"\\nSkewness of '{target_variable}': {skewness:.3f}\")\n",
    "\n",
    "# Visualize the distribution using a histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df_subset[target_variable], kde=True, bins=30, color='indigo')\n",
    "plt.title(f'Distribution of {target_variable}', fontsize=16)\n",
    "plt.xlabel('Fuel Efficiency (MPG)', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.grid(axis='y', alpha=0.5)\n",
    "plt.show()\n",
    "\n",
    "# Conclusion based on the skewness value and plot\n",
    "if skewness > 0.5:\n",
    "    print(\"\\nCONCLUSION: The 'fuel_efficiency_mpg' distribution is positively (right) skewed, indicating a **long tail**.\")\n",
    "    print(\"This suggests that a logarithmic transformation (log(MPG)) might be beneficial for the regression model.\")\n",
    "elif skewness < -0.5:\n",
    "    print(\"\\nCONCLUSION: The 'fuel_efficiency_mpg' distribution is negatively (left) skewed.\")\n",
    "else:\n",
    "    print(\"\\nCONCLUSION: The 'fuel_efficiency_mpg' distribution is fairly symmetric.\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6b9cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in the subset\n",
    "print(\"\\n--- Missing Value Count per Column ---\")\n",
    "missing_values = df_subset.isnull().sum()\n",
    "print(missing_values)\n",
    "\n",
    "# 4. Identify the column with missing values\n",
    "missing_column = missing_values[missing_values > 0].index.tolist()\n",
    "\n",
    "print(\"\\n--- Result ---\")\n",
    "if missing_column:\n",
    "    print(f\"The column with missing values is: '{missing_column[0]}'.\")\n",
    "else:\n",
    "    print(\"No missing values found in the selected columns.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81351f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "# Impute missing 'horsepower' values with the median (93.0)\n",
    "median_horsepower = df['horsepower'].median() # This should be 93.0\n",
    "print(\"Median horsepower for imputation:\", median_horsepower)\n",
    "\n",
    "df['horsepower'] = df['horsepower'].fillna(median_horsepower)\n",
    "\n",
    "# 2. Shuffle the dataset\n",
    "np.random.seed(SEED)\n",
    "n = len(df)\n",
    "n_val = int(0.2 * n)  # 20% for validation\n",
    "n_test = int(0.2 * n) # 20% for testing\n",
    "n_train = n - n_val - n_test # 60% for training\n",
    "\n",
    "# Create shuffled indices\n",
    "idx = np.arange(n)\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "# Apply shuffled indices to the DataFrame\n",
    "df_shuffled = df.iloc[idx]\n",
    "\n",
    "# 3. Split the data\n",
    "df_train = df_shuffled.iloc[:n_train].copy()\n",
    "df_val = df_shuffled.iloc[n_train:n_train + n_val].copy()\n",
    "df_test = df_shuffled.iloc[n_train + n_val:].copy()\n",
    "\n",
    "# 4. Create the target variable arrays for the train/val/test sets\n",
    "# Note: It's good practice to apply the log transformation here, \n",
    "# but for now, we will create the raw target variable as instructed.\n",
    "# If you want to use the log transformation, you'd apply it to the y_train/val/test.\n",
    "\n",
    "y_train = df_train['fuel_efficiency_mpg'].values\n",
    "y_val = df_val['fuel_efficiency_mpg'].values\n",
    "y_test = df_test['fuel_efficiency_mpg'].values\n",
    "\n",
    "# Remove the target variable from the feature sets (X)\n",
    "del df_train['fuel_efficiency_mpg']\n",
    "del df_val['fuel_efficiency_mpg']\n",
    "del df_test['fuel_efficiency_mpg']\n",
    "\n",
    "# 5. Output confirmation\n",
    "print(\"--- Dataset Preparation Summary ---\")\n",
    "print(f\"Total rows: {n}\")\n",
    "print(f\"Train set size (60%): {len(df_train)}\")\n",
    "print(f\"Validation set size (20%): {len(df_val)}\")\n",
    "print(f\"Test set size (20%): {len(df_test)}\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "# Verify no missing values remain in the training set features\n",
    "print(f\"'horsepower' missing values in train set after imputation: {df_train['horsepower'].isnull().sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014cc70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# --- Configuration ---\n",
    "url = \"https://raw.githubusercontent.com/alexeygrigorev/datasets/master/car_fuel_efficiency.csv\"\n",
    "SEED = 42\n",
    "REQUIRED_COLUMNS = [\n",
    "    'engine_displacement',\n",
    "    'horsepower',\n",
    "    'vehicle_weight',\n",
    "    'model_year',\n",
    "    'fuel_efficiency_mpg'\n",
    "]\n",
    "TARGET = 'fuel_efficiency_mpg'\n",
    "\n",
    "# --- Linear Regression Functions from Lectures ---\n",
    "\n",
    "def train_linear_regression(X, y):\n",
    "    \"\"\"Trains a simple linear regression model.\"\"\"\n",
    "    # Add the bias column (column of ones)\n",
    "    ones = np.ones(X.shape[0])\n",
    "    X = np.column_stack([ones, X])\n",
    "\n",
    "    # Normal Equation: w = (X^T * X)^-1 * (X^T * y)\n",
    "    XTX = X.T.dot(X)\n",
    "    XTX_inv = np.linalg.inv(XTX)\n",
    "    w = XTX_inv.dot(X.T).dot(y)\n",
    "\n",
    "    # w0 is the bias, w[1:] are the weights for the features\n",
    "    return w[0], w[1:]\n",
    "\n",
    "def rmse(y, y_pred):\n",
    "    \"\"\"Calculates the Root Mean Squared Error (RMSE).\"\"\"\n",
    "    error = y - y_pred\n",
    "    se = error ** 2\n",
    "    mse = se.mean()\n",
    "    return np.sqrt(mse)\n",
    "\n",
    "# --- Data Preparation (Reload and Split) ---\n",
    "\n",
    "df = pd.read_csv(url)\n",
    "df = df[REQUIRED_COLUMNS]\n",
    "\n",
    "# Apply train/val/test split\n",
    "n = len(df)\n",
    "n_val = int(0.2 * n)\n",
    "n_test = int(0.2 * n)\n",
    "n_train = n - n_val - n_test\n",
    "\n",
    "np.random.seed(SEED)\n",
    "idx = np.arange(n)\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "df_shuffled = df.iloc[idx].reset_index(drop=True)\n",
    "\n",
    "df_train = df_shuffled.iloc[:n_train].copy()\n",
    "df_val = df_shuffled.iloc[n_train:n_train + n_val].copy()\n",
    "df_test = df_shuffled.iloc[n_train + n_val:].copy()\n",
    "\n",
    "# Extract target variables (y)\n",
    "y_train = df_train[TARGET].values\n",
    "y_val = df_val[TARGET].values\n",
    "y_test = df_test[TARGET].values\n",
    "\n",
    "# Drop the target from feature dataframes (X)\n",
    "del df_train[TARGET]\n",
    "del df_val[TARGET]\n",
    "del df_test[TARGET]\n",
    "\n",
    "# Identify the missing value column\n",
    "MISSING_COL = 'horsepower'\n",
    "train_mean = df_train[MISSING_COL].mean()\n",
    "\n",
    "print(f\"Calculated training mean for 'horsepower': {round(train_mean, 2)}\\n\")\n",
    "\n",
    "# --- Imputation Strategy 1: Fill with 0 ---\n",
    "\n",
    "print(\"--- Strategy 1: Impute with 0 ---\")\n",
    "X_train_0 = df_train.fillna(0).values\n",
    "X_val_0 = df_val.fillna(0).values\n",
    "\n",
    "# Train the model\n",
    "w0_0, w_0 = train_linear_regression(X_train_0, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "y_pred_0 = w0_0 + X_val_0.dot(w_0)\n",
    "\n",
    "# Evaluate RMSE\n",
    "rmse_0 = rmse(y_val, y_pred_0)\n",
    "print(f\"RMSE (Impute with 0): {rmse_0:.4f}\")\n",
    "print(f\"Rounded RMSE (Impute with 0): {round(rmse_0, 2)}\")\n",
    "\n",
    "# --- Imputation Strategy 2: Fill with Training Mean ---\n",
    "\n",
    "print(\"\\n--- Strategy 2: Impute with Training Mean ---\")\n",
    "X_train_mean = df_train.fillna(train_mean).values\n",
    "X_val_mean = df_val.fillna(train_mean).values\n",
    "\n",
    "# Train the model\n",
    "w0_mean, w_mean = train_linear_regression(X_train_mean, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "y_pred_mean = w0_mean + X_val_mean.dot(w_mean)\n",
    "\n",
    "# Evaluate RMSE\n",
    "rmse_mean = rmse(y_val, y_pred_mean)\n",
    "print(f\"RMSE (Impute with Mean): {rmse_mean:.4f}\")\n",
    "print(f\"Rounded RMSE (Impute with Mean): {round(rmse_mean, 2)}\")\n",
    "\n",
    "print(\"\\n--- Final Comparison ---\")\n",
    "if round(rmse_0, 2) < round(rmse_mean, 2):\n",
    "    print(\"Option 'With 0' gives better RMSE.\")\n",
    "elif round(rmse_mean, 2) < round(rmse_0, 2):\n",
    "    print(\"Option 'With mean' gives better RMSE.\")\n",
    "else:\n",
    "    print(\"Both options are equally good.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2908c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# --- Configuration ---\n",
    "url = \"https://raw.githubusercontent.com/alexeygrigorev/datasets/master/car_fuel_efficiency.csv\"\n",
    "SEED = 42\n",
    "REQUIRED_COLUMNS = [\n",
    "    'engine_displacement', 'horsepower', 'vehicle_weight', 'model_year', 'fuel_efficiency_mpg'\n",
    "]\n",
    "TARGET = 'fuel_efficiency_mpg'\n",
    "REGULARIZATION_PARAMS = [0, 0.01, 0.1, 1, 5, 10, 100]\n",
    "\n",
    "# --- Linear Regression Functions ---\n",
    "\n",
    "def train_linear_regression_reg(X, y, r):\n",
    "    \"\"\"Trains a regularized (Ridge) linear regression model.\"\"\"\n",
    "    # Add the bias column (column of ones)\n",
    "    ones = np.ones(X.shape[0])\n",
    "    X = np.column_stack([ones, X])\n",
    "\n",
    "    # Calculate XTX with regularization term\n",
    "    XTX = X.T.dot(X)\n",
    "    \n",
    "    # Create the identity matrix and add the regularization term (r * I)\n",
    "    # The bias term (first element) should NOT be regularized, so the top-left element is 0.\n",
    "    reg = r * np.eye(XTX.shape[0])\n",
    "    reg[0, 0] = 0 \n",
    "    \n",
    "    XTX = XTX + reg\n",
    "\n",
    "    # Solve for weights w = (XTX + rI)^-1 * (X^T * y)\n",
    "    XTX_inv = np.linalg.inv(XTX)\n",
    "    w = XTX_inv.dot(X.T).dot(y)\n",
    "\n",
    "    return w[0], w[1:]\n",
    "\n",
    "def rmse(y, y_pred):\n",
    "    \"\"\"Calculates the Root Mean Squared Error (RMSE).\"\"\"\n",
    "    error = y - y_pred\n",
    "    se = error ** 2\n",
    "    mse = se.mean()\n",
    "    return np.sqrt(mse)\n",
    "\n",
    "# --- Data Preparation (Load, Split, Impute) ---\n",
    "\n",
    "# Load and filter data\n",
    "df = pd.read_csv(url)\n",
    "df = df[REQUIRED_COLUMNS]\n",
    "\n",
    "# Split indices and data\n",
    "n = len(df)\n",
    "n_val = int(0.2 * n)\n",
    "n_test = int(0.2 * n)\n",
    "n_train = n - n_val - n_test\n",
    "\n",
    "np.random.seed(SEED)\n",
    "idx = np.arange(n)\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "df_shuffled = df.iloc[idx].reset_index(drop=True)\n",
    "\n",
    "df_train = df_shuffled.iloc[:n_train].copy()\n",
    "df_val = df_shuffled.iloc[n_train:n_train + n_val].copy()\n",
    "df_test = df_shuffled.iloc[n_train + n_val:].copy()\n",
    "\n",
    "# Extract target variables (y)\n",
    "y_train = df_train[TARGET].values\n",
    "y_val = df_val[TARGET].values\n",
    "y_test = df_test[TARGET].values\n",
    "\n",
    "# Drop the target from feature dataframes (X)\n",
    "del df_train[TARGET]\n",
    "del df_val[TARGET]\n",
    "del df_test[TARGET]\n",
    "\n",
    "# Impute all missing 'horsepower' values with 0\n",
    "df_train = df_train.fillna(0)\n",
    "df_val = df_val.fillna(0)\n",
    "df_test = df_test.fillna(0)\n",
    "\n",
    "# Convert DataFrames to numpy arrays for training\n",
    "X_train = df_train.values\n",
    "X_val = df_val.values\n",
    "\n",
    "# --- Tuning the Regularization Parameter (r) ---\n",
    "\n",
    "results = []\n",
    "best_rmse = float('inf')\n",
    "best_r = -1\n",
    "\n",
    "print(\"--- Ridge Regression Tuning Results ---\")\n",
    "for r in REGULARIZATION_PARAMS:\n",
    "    # Train model\n",
    "    w0, w = train_linear_regression_reg(X_train, y_train, r=r)\n",
    "    \n",
    "    # Predict and evaluate on validation set\n",
    "    y_pred = w0 + X_val.dot(w)\n",
    "    score = rmse(y_val, y_pred)\n",
    "    rounded_score = round(score, 2)\n",
    "    \n",
    "    # Store results and check for best r\n",
    "    results.append({'r': r, 'rmse': rounded_score})\n",
    "    print(f\"r = {r:<5}: RMSE = {rounded_score}\")\n",
    "\n",
    "    # Logic to select the smallest r if scores are equal\n",
    "    if rounded_score < best_rmse:\n",
    "        best_rmse = rounded_score\n",
    "        best_r = r\n",
    "    elif rounded_score == best_rmse and r < best_r:\n",
    "        best_r = r\n",
    "\n",
    "print(\"-\" * 40)\n",
    "print(f\"The best RMSE is {best_rmse}, achieved with the smallest r of: {best_r}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3b8ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# --- Configuration ---\n",
    "url = \"https://raw.githubusercontent.com/alexeygrigorev/datasets/master/car_fuel_efficiency.csv\"\n",
    "SEEDS = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "REQUIRED_COLUMNS = [\n",
    "    'engine_displacement', 'horsepower', 'vehicle_weight', 'model_year', 'fuel_efficiency_mpg'\n",
    "]\n",
    "TARGET = 'fuel_efficiency_mpg'\n",
    "\n",
    "# --- Linear Regression Functions ---\n",
    "\n",
    "def train_linear_regression(X, y):\n",
    "    \"\"\"Trains a simple linear regression model (no regularization).\"\"\"\n",
    "    ones = np.ones(X.shape[0])\n",
    "    X = np.column_stack([ones, X])\n",
    "    \n",
    "    # Solve for weights w = (X^T * X)^-1 * (X^T * y)\n",
    "    XTX = X.T.dot(X)\n",
    "    XTX_inv = np.linalg.inv(XTX)\n",
    "    w = XTX_inv.dot(X.T).dot(y)\n",
    "\n",
    "    return w[0], w[1:]\n",
    "\n",
    "def rmse(y, y_pred):\n",
    "    \"\"\"Calculates the Root Mean Squared Error (RMSE).\"\"\"\n",
    "    error = y - y_pred\n",
    "    se = error ** 2\n",
    "    mse = se.mean()\n",
    "    return np.sqrt(mse)\n",
    "\n",
    "# --- Main Analysis Loop ---\n",
    "\n",
    "df_original = pd.read_csv(url)\n",
    "df_original = df_original[REQUIRED_COLUMNS]\n",
    "\n",
    "scores = []\n",
    "\n",
    "print(\"--- RMSE Scores by Seed ---\")\n",
    "for seed in SEEDS:\n",
    "    # 1. Prepare data for the current seed\n",
    "    df = df_original.copy()\n",
    "    \n",
    "    n = len(df)\n",
    "    n_val = int(0.2 * n)\n",
    "    n_test = int(0.2 * n)\n",
    "    n_train = n - n_val - n_test\n",
    "\n",
    "    # 2. Shuffle and split using the current seed\n",
    "    np.random.seed(seed)\n",
    "    idx = np.arange(n)\n",
    "    np.random.shuffle(idx)\n",
    "\n",
    "    df_shuffled = df.iloc[idx].reset_index(drop=True)\n",
    "\n",
    "    df_train = df_shuffled.iloc[:n_train].copy()\n",
    "    df_val = df_shuffled.iloc[n_train:n_train + n_val].copy()\n",
    "\n",
    "    # 3. Extract target variables (y)\n",
    "    y_train = df_train[TARGET].values\n",
    "    y_val = df_val[TARGET].values\n",
    "\n",
    "    # 4. Drop the target from feature dataframes (X)\n",
    "    del df_train[TARGET]\n",
    "    del df_val[TARGET]\n",
    "\n",
    "    # 5. Impute all missing 'horsepower' values with 0\n",
    "    X_train = df_train.fillna(0).values\n",
    "    X_val = df_val.fillna(0).values\n",
    "\n",
    "    # 6. Train the model (no regularization)\n",
    "    w0, w = train_linear_regression(X_train, y_train)\n",
    "\n",
    "    # 7. Predict and evaluate on validation set\n",
    "    y_pred = w0 + X_val.dot(w)\n",
    "    score = rmse(y_val, y_pred)\n",
    "    \n",
    "    scores.append(score)\n",
    "    print(f\"Seed {seed}: RMSE = {score:.4f}\")\n",
    "\n",
    "# --- Final Calculation ---\n",
    "\n",
    "std_score = np.std(scores)\n",
    "rounded_std = round(std_score, 3)\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(f\"RMSE Scores: {np.round(scores, 4)}\")\n",
    "print(f\"Standard Deviation (STD) of RMSE scores: {std_score:.5f}\")\n",
    "print(f\"Rounded STD: {rounded_std}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ff9722",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# --- Configuration ---\n",
    "url = \"https://raw.githubusercontent.com/alexeygrigorev/datasets/master/car_fuel_efficiency.csv\"\n",
    "SEED = 9\n",
    "REGULARIZATION_R = 0.001\n",
    "REQUIRED_COLUMNS = [\n",
    "    'engine_displacement', 'horsepower', 'vehicle_weight', 'model_year', 'fuel_efficiency_mpg'\n",
    "]\n",
    "TARGET = 'fuel_efficiency_mpg'\n",
    "\n",
    "# --- Linear Regression Functions ---\n",
    "\n",
    "def train_linear_regression_reg(X, y, r):\n",
    "    \"\"\"Trains a regularized (Ridge) linear regression model.\"\"\"\n",
    "    # Add the bias column (column of ones)\n",
    "    ones = np.ones(X.shape[0])\n",
    "    X = np.column_stack([ones, X])\n",
    "\n",
    "    # Calculate XTX with regularization term\n",
    "    XTX = X.T.dot(X)\n",
    "    \n",
    "    # Create the identity matrix and add the regularization term (r * I)\n",
    "    # The bias term (first element) should NOT be regularized.\n",
    "    reg = r * np.eye(XTX.shape[0])\n",
    "    reg[0, 0] = 0 \n",
    "    \n",
    "    XTX = XTX + reg\n",
    "\n",
    "    # Solve for weights w = (XTX + rI)^-1 * (X^T * y)\n",
    "    XTX_inv = np.linalg.inv(XTX)\n",
    "    w = XTX_inv.dot(X.T).dot(y)\n",
    "\n",
    "    return w[0], w[1:]\n",
    "\n",
    "def rmse(y, y_pred):\n",
    "    \"\"\"Calculates the Root Mean Squared Error (RMSE).\"\"\"\n",
    "    error = y - y_pred\n",
    "    se = error ** 2\n",
    "    mse = se.mean()\n",
    "    return np.sqrt(mse)\n",
    "\n",
    "# --- Data Preparation (Load, Split, Combine) ---\n",
    "\n",
    "# Load and filter data\n",
    "df = pd.read_csv(url)\n",
    "df = df[REQUIRED_COLUMNS]\n",
    "\n",
    "# Split indices and data\n",
    "n = len(df)\n",
    "n_val = int(0.2 * n)\n",
    "n_test = int(0.2 * n)\n",
    "n_train = n - n_val - n_test\n",
    "\n",
    "# 1. Shuffle and split using seed 9\n",
    "np.random.seed(SEED)\n",
    "idx = np.arange(n)\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "df_shuffled = df.iloc[idx].reset_index(drop=True)\n",
    "\n",
    "# Split into train/val (for combined set) and test\n",
    "df_train_val = df_shuffled.iloc[:n_train + n_val].copy()\n",
    "df_test = df_shuffled.iloc[n_train + n_val:].copy()\n",
    "\n",
    "# Extract target variables (y)\n",
    "y_train_val = df_train_val[TARGET].values\n",
    "y_test = df_test[TARGET].values\n",
    "\n",
    "# Drop the target from feature dataframes (X)\n",
    "del df_train_val[TARGET]\n",
    "del df_test[TARGET]\n",
    "\n",
    "# 2. Impute all missing 'horsepower' values with 0\n",
    "X_train_val = df_train_val.fillna(0).values\n",
    "X_test = df_test.fillna(0).values\n",
    "\n",
    "# --- Training and Evaluation ---\n",
    "\n",
    "print(f\"--- Final Evaluation (Seed {SEED}, r={REGULARIZATION_R}) ---\")\n",
    "\n",
    "# Train the model on the combined Train + Validation set\n",
    "w0, w = train_linear_regression_reg(X_train_val, y_train_val, r=REGULARIZATION_R)\n",
    "\n",
    "# Predict on the unseen Test set\n",
    "y_pred_test = w0 + X_test.dot(w)\n",
    "\n",
    "# Evaluate RMSE\n",
    "rmse_test = rmse(y_test, y_pred_test)\n",
    "rounded_rmse = round(rmse_test, 2)\n",
    "\n",
    "print(f\"RMSE on Test Dataset: {rmse_test:.4f}\")\n",
    "print(f\"Rounded RMSE on Test Dataset: {rounded_rmse}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-zoomcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
