{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOLG7XUwRZRIqRC4RNIYsRx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahmed123234/zoomcamp-ML/blob/main/homework-03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "!wget -O course_lead_scoring.csv https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vp2B_XiwxYE9",
        "outputId": "cc9c0905-cf0f-4ef6-d8a6-0a0a805d76d7"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-10-15 09:51:33--  https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 80876 (79K) [text/plain]\n",
            "Saving to: ‘course_lead_scoring.csv’\n",
            "\n",
            "\rcourse_lead_scoring   0%[                    ]       0  --.-KB/s               \rcourse_lead_scoring 100%[===================>]  78.98K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2025-10-15 09:51:33 (13.2 MB/s) - ‘course_lead_scoring.csv’ saved [80876/80876]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXIm554Hw6X3",
        "outputId": "b8015424-1173-4a24-cfe5-8736cab949a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Initial Dataset Load and Inspection ---\n",
            "Dataset size: 1462 rows, 9 columns\n",
            "\n",
            "First 5 rows:\n",
            "    lead_source    industry  number_of_courses_viewed  annual_income  \\\n",
            "0      paid_ads         NaN                         1        79450.0   \n",
            "1  social_media      retail                         1        46992.0   \n",
            "2        events  healthcare                         5        78796.0   \n",
            "3      paid_ads      retail                         2        83843.0   \n",
            "4      referral   education                         3        85012.0   \n",
            "\n",
            "  employment_status       location  interaction_count  lead_score  converted  \n",
            "0        unemployed  south_america                  4        0.94          1  \n",
            "1          employed  south_america                  1        0.80          0  \n",
            "2        unemployed      australia                  3        0.69          1  \n",
            "3               NaN      australia                  1        0.87          0  \n",
            "4     self_employed         europe                  3        0.62          1  \n",
            "----------------------------------------\n",
            "Missing values BEFORE imputation:\n",
            "lead_source          128\n",
            "industry             134\n",
            "annual_income        181\n",
            "employment_status    100\n",
            "location              63\n",
            "dtype: int64\n",
            "----------------------------------------\n",
            "Missing values AFTER imputation:\n",
            "Series([], dtype: int64)\n",
            "----------------------------------------\n",
            "Data types check (Target is not yet separated):\n",
            "lead_source                  object\n",
            "industry                     object\n",
            "number_of_courses_viewed      int64\n",
            "annual_income               float64\n",
            "employment_status            object\n",
            "location                     object\n",
            "interaction_count             int64\n",
            "lead_score                  float64\n",
            "converted                     int64\n",
            "dtype: object\n",
            "----------------------------------------\n",
            "Step 1 Complete: Data is loaded and missing values have been handled.\n"
          ]
        }
      ],
      "source": [
        "# --- 1. Load the Dataset ---\n",
        "df = pd.read_csv('course_lead_scoring.csv')\n",
        "\n",
        "# Clean up column names by lowercasing and replacing spaces\n",
        "df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
        "\n",
        "print(\"--- Initial Dataset Load and Inspection ---\")\n",
        "print(f\"Dataset size: {len(df)} rows, {len(df.columns)} columns\")\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "print(df.head())\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# --- 2. Identify Feature Types and Check Missing Values ---\n",
        "numerical_features = ['annual_income', 'number_of_courses_viewed', 'interaction_count', 'lead_score']\n",
        "categorical_features = ['industry', 'location', 'lead_source', 'employment_status']\n",
        "target = 'converted'\n",
        "\n",
        "print(\"Missing values BEFORE imputation:\")\n",
        "print(df.isnull().sum()[df.isnull().sum() > 0])\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# --- 3. Data Preparation: Handle Missing Values ---\n",
        "\n",
        "# Impute numerical features with 0.0\n",
        "for col in numerical_features:\n",
        "    df[col] = df[col].fillna(0.0)\n",
        "\n",
        "# Impute categorical features with 'NA'\n",
        "for col in categorical_features:\n",
        "    df[col] = df[col].fillna('NA')\n",
        "\n",
        "print(\"Missing values AFTER imputation:\")\n",
        "print(df.isnull().sum()[df.isnull().sum() > 0])\n",
        "\n",
        "# Verify data types and show clean data\n",
        "print(\"-\" * 40)\n",
        "print(\"Data types check (Target is not yet separated):\")\n",
        "print(df.dtypes)\n",
        "\n",
        "print(\"-\" * 40)\n",
        "print(\"Step 1 Complete: Data is loaded and missing values have been handled.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Question 1 Calculation: 1: The Mode of 'industry' ---\n",
        "industry_mode = df['industry'].mode().iloc[0]\n",
        "\n",
        "print(f\"The total number of observations in 'industry' is: {len(df)}\")\n",
        "print(f\"The most frequent observation (mode) for the column 'industry' is: '{industry_mode}'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTibj5GcxRE9",
        "outputId": "4c9c1a63-ecae-4233-e2b7-ced341a4dd8c"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The total number of observations in 'industry' is: 1462\n",
            "The most frequent observation (mode) for the column 'industry' is: 'retail'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Question 2: Correlation Matrix ---\n",
        "print(\"--- Question 2 ---\")\n",
        "# Calculate correlation matrix for numerical features\n",
        "corr_matrix = df[numerical_features].corr()\n",
        "\n",
        "# Extract the required correlation pairs\n",
        "pairs = {\n",
        "    'interaction_count vs lead_score': corr_matrix.loc['interaction_count', 'lead_score'],\n",
        "    'number_of_courses_viewed vs lead_score': corr_matrix.loc['number_of_courses_viewed', 'lead_score'],\n",
        "    'number_of_courses_viewed vs interaction_count': corr_matrix.loc['number_of_courses_viewed', 'interaction_count'],\n",
        "    'annual_income vs interaction_count': corr_matrix.loc['annual_income', 'interaction_count']\n",
        "}\n",
        "\n",
        "# Find the pair with the biggest absolute correlation\n",
        "max_corr_pair = max(pairs.items(), key=lambda item: abs(item[1]))\n",
        "\n",
        "print(\"Correlation Pairs:\")\n",
        "for pair, corr in pairs.items():\n",
        "    print(f\"  {pair}: {corr:.4f}\")\n",
        "print(f\"The two features with the biggest correlation (absolute value) are: {max_corr_pair[0]} ({max_corr_pair[1]:.4f})\")\n",
        "# The biggest correlation is between 'number_of_courses_viewed' and 'interaction_count'\n",
        "print(\"-\" * 20)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJU8Cz9xz8t1",
        "outputId": "72fa135e-3cb8-436c-f1a3-d4efb6cd3f17"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Question 2 ---\n",
            "Correlation Pairs:\n",
            "  interaction_count vs lead_score: 0.0099\n",
            "  number_of_courses_viewed vs lead_score: -0.0049\n",
            "  number_of_courses_viewed vs interaction_count: -0.0236\n",
            "  annual_income vs interaction_count: 0.0270\n",
            "The two features with the biggest correlation (absolute value) are: annual_income vs interaction_count (0.0270)\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# --- Split Data into Train (60%), Validation (20%), and Test (20%) ---\n",
        "\n",
        "print(\"--- Data Splitting ---\")\n",
        "\n",
        "# Split into Train (80%) and test (20%)\n",
        "df_full_train, df_test =  train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Split Train (80%) into Validation (20%) and Train (60%)\n",
        "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=42)\n",
        "\n",
        "\n",
        "df_train = df_train.reset_index(drop=True)\n",
        "df_val = df_val.reset_index(drop=True)\n",
        "df_test = df_test.reset_index(drop=True)\n",
        "\n",
        "# determine the y value for the target coulmn\n",
        "TARGET = 'converted'\n",
        "y_train = df_train[TARGET].values\n",
        "y_val = df_val[TARGET].values\n",
        "y_test = df_test[TARGET].values\n",
        "\n",
        "# del the y value from the trained data\n",
        "del df_train[TARGET]\n",
        "del df_val[TARGET]\n",
        "del df_test[TARGET]\n",
        "\n",
        "\n",
        "\n",
        "# --- 4. Verification and Output ---\n",
        "print(\"--- Data Split Verification ---\")\n",
        "print(f\"Total dataset size: {len(df)} rows\")\n",
        "print(\"-\" * 35)\n",
        "print(f\"Training set size (60%): {len(df_train)} rows\")\n",
        "print(f\"Validation set size (20%): {len(df_val)} rows\")\n",
        "print(f\"Test set size (20%): {len(df_test)} rows\")\n",
        "print(\"-\" * 35)\n",
        "print(\"Data split successfully into 60/20/20 distribution.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDBtNi4j1rpX",
        "outputId": "7ca868c3-8b55-4458-d5ed-7519ab40c652"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Data Splitting ---\n",
            "--- Data Split Verification ---\n",
            "Total dataset size: 1462 rows\n",
            "-----------------------------------\n",
            "Training set size (60%): 876 rows\n",
            "Validation set size (20%): 293 rows\n",
            "Test set size (20%): 293 rows\n",
            "-----------------------------------\n",
            "Data split successfully into 60/20/20 distribution.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Question 3: Mutual Information ---\n",
        "from sklearn.metrics import mutual_info_score\n",
        "\n",
        "def mutual_info_score_binary(series):\n",
        "    return mutual_info_score(series, y_train)\n",
        "\n",
        "# apply for every categorical_features\n",
        "mi = df_train[categorical_features].apply(mutual_info_score_binary)\n",
        "mi = round(mi.sort_values(ascending=False), 2)\n",
        "\n",
        "print(\"--- Mutual Information Scores ---\")\n",
        "print(mi)\n",
        "print(\"-\" * 35)\n",
        "\n",
        "# find the biggest matual information feature\n",
        "print(f\"The feature with the biggest mutual information is: {mi.index[0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EJkkiY82oxp",
        "outputId": "dca1ba5b-b9f6-4859-d4de-daceb598c1e8"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Mutual Information Scores ---\n",
            "lead_source          0.04\n",
            "employment_status    0.01\n",
            "industry             0.01\n",
            "location             0.00\n",
            "dtype: float64\n",
            "-----------------------------------\n",
            "The feature with the biggest mutual information is: lead_source\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# --- Question 4: Logistic Regression Baseline ---\n",
        "\n",
        "print(\"--- Logistic Regression Baseline ---\")\n",
        "\n",
        "# --- Feature Preparation for Model Training ---\n",
        "dv = DictVectorizer(sparse=False)\n",
        "train_dicts = df_train[categorical_features + numerical_features].to_dict(orient='records')\n",
        "X_train = dv.fit_transform(train_dicts)\n",
        "\n",
        "val_dicts = df_val[categorical_features + numerical_features].to_dict(orient='records')\n",
        "X_val = dv.transform(val_dicts)\n",
        "\n",
        "\n",
        "# --- Model Training ---\n",
        "print(\"--- Logistic Regression Training ---\")\n",
        "\n",
        "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Calculate the accuracy on the validation dataset and round it to 2 decimal digits.\n",
        "# y_pred_val = model.predict_proba(X_val)[:, 1]\n",
        "# accuracy_baseline = accuracy_score(y_val, (y_pred_val >= 0.5))\n",
        "# accuracy_q4 = round(accuracy_baseline, 2)\n",
        "# print(f\"The accuracy of the model on the validation dataset is: {accuracy_q4}\")\n",
        "\n",
        "# y_pred = y_pred_val >= 0.5\n",
        "# print(round((y_pred == y_val).mean(), 2))\n",
        "\n",
        "accuracy = round(model.score(X_val, y_val), 2)\n",
        "print(f\"The accuracy of the model on the validation dataset is: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "api1yofA8OEc",
        "outputId": "7368f187-1540-402e-adab-701e6830292e"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Logistic Regression Baseline ---\n",
            "--- Logistic Regression Training ---\n",
            "The accuracy of the model on the validation dataset is: 0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(\"Processed training data shape:\", X_train_processed.shape)\n",
        "print(\"Processed training data shape:\", X_train.shape)\n",
        "df_train.lead_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "id": "nwhe9eWXLdgV",
        "outputId": "9f94b610-abe6-458e-d0aa-77583e77be38"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed training data shape: (876, 31)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      0.03\n",
              "1      0.77\n",
              "2      0.59\n",
              "3      0.34\n",
              "4      0.98\n",
              "       ... \n",
              "871    0.33\n",
              "872    0.18\n",
              "873    0.75\n",
              "874    0.65\n",
              "875    0.54\n",
              "Name: lead_score, Length: 876, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lead_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>871</th>\n",
              "      <td>0.33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>872</th>\n",
              "      <td>0.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>873</th>\n",
              "      <td>0.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>874</th>\n",
              "      <td>0.65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>875</th>\n",
              "      <td>0.54</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>876 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# --- Question 5: Feature Elimination ---\n",
        "\n",
        "print(\"--- Question 5: Feature Elimination ---\")\n",
        "\n",
        "features_to_eliminate = ['industry', 'employment_status', 'lead_score']\n",
        "baseline_accuracy = model.score(X_val, y_val)\n",
        "print(f\"Baseline accuracy: {baseline_accuracy}\")\n",
        "\n",
        "accuracy_differences = {}\n",
        "\n",
        "for feature in features_to_eliminate:\n",
        "    # Create modified datasets by excluding the current feature\n",
        "    train_dicts_modified = df_train.drop(columns=[feature]).to_dict(orient='records')\n",
        "    X_train_modified = dv.fit_transform(train_dicts_modified)\n",
        "    val_dicts_modified = df_val.drop(columns=[feature]).to_dict(orient='records')\n",
        "    X_val_modified = dv.transform(val_dicts_modified)\n",
        "\n",
        "    # Train a new model without the current feature\n",
        "    model_modified = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
        "    model_modified.fit(X_train_modified, y_train)\n",
        "\n",
        "    # Calculate accuracy on the modified validation data\n",
        "    # y_pred_val_modified = model_modified.predict(X_val_modified)\n",
        "    # accuracy_modified = accuracy_score(y_val, y_pred_val_modified)\n",
        "    accuracy_modified = model_modified.score(X_val_modified, y_val)\n",
        "\n",
        "    # Calculate the accuracy difference\n",
        "    accuracy_difference = baseline_accuracy - accuracy_modified\n",
        "    accuracy_differences[feature] = accuracy_difference\n",
        "\n",
        "    print(f\"Accuracy without '{feature}': {accuracy_modified}, Difference: {accuracy_difference}\")\n",
        "\n",
        "# Find the feature with the smallest accuracy difference\n",
        "feature_with_smallest_difference = min(accuracy_differences, key=accuracy_differences.get)\n",
        "\n",
        "print(f\"\\nThe feature with the smallest accuracy difference is: '{feature_with_smallest_difference}'\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pL_JqGPYAiN5",
        "outputId": "12e97eb3-a426-4f6c-e6bf-8c8288f96040"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Question 5: Feature Elimination ---\n",
            "Baseline accuracy: 0.6996587030716723\n",
            "Accuracy without 'industry': 0.6996587030716723, Difference: 0.0\n",
            "Accuracy without 'employment_status': 0.6962457337883959, Difference: 0.0034129692832763903\n",
            "Accuracy without 'lead_score': 0.7064846416382252, Difference: -0.0068259385665528916\n",
            "\n",
            "The feature with the smallest accuracy difference is: 'lead_score'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Question 6: Regularized Logistic Regression (Tuning C) ---\n",
        "\n",
        "print(\"--- Question 6: Regularized Logistic Regression (Tuning C) ---\")\n",
        "\n",
        "c_parameters = [0.01, 0.1, 1, 10, 100]\n",
        "\n",
        "# initilize the accuracy_dict\n",
        "accuracy_dict = {}\n",
        "\n",
        "# train the model with different parameter as c value\n",
        "for c in c_parameters:\n",
        "    model = LogisticRegression(solver='liblinear', C=c, max_iter=1000, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "    accuracy = round(model.score(X_val, y_val), 3)\n",
        "    # print(f\"Accuracy with C={parameter}: {accuracy}\")\n",
        "    print(f\"C={c}: Validation Accuracy (rounded to 3 decimals): {accuracy}\")\n",
        "\n",
        "\n",
        "    accuracy_dict[c] = accuracy\n",
        "\n",
        "# find the max one\n",
        "max_accuracy = max(accuracy_dict, key=accuracy_dict.get)\n",
        "\n",
        "print(f\"The parameter with the biggest accuracy is: {max_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63SFF46oOQhu",
        "outputId": "8f116a05-d508-470d-8a49-d12d861177d4"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Question 6: Regularized Logistic Regression (Tuning C) ---\n",
            "C=0.01: Validation Accuracy (rounded to 3 decimals): 0.7\n",
            "C=0.1: Validation Accuracy (rounded to 3 decimals): 0.7\n",
            "C=1: Validation Accuracy (rounded to 3 decimals): 0.7\n",
            "C=10: Validation Accuracy (rounded to 3 decimals): 0.7\n",
            "C=100: Validation Accuracy (rounded to 3 decimals): 0.7\n",
            "The parameter with the biggest accuracy is: 0.01\n"
          ]
        }
      ]
    }
  ]
}